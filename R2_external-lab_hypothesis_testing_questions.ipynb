{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xx5CxeVubU3W"
   },
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6OR23eWKbU3X"
   },
   "source": [
    "The purpose of the test is to tell if there is any significant difference between two data sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "604OoWnTbU3Z"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-il1iBSbU3b"
   },
   "source": [
    "This module covers,\n",
    "\n",
    "1) One sample and Two sample t-tests\n",
    "\n",
    "2) ANOVA\n",
    "\n",
    "3) Type I and Type II errors\n",
    "\n",
    "4) Chi-Squared Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2yYl5cvbU3c"
   },
   "source": [
    "## Question 1 \n",
    "\n",
    "*A student is trying to decide between two GPUs. He want to use the GPU for his research to run Deep learning algorithms, so the only thing he is concerned with is speed.*\n",
    "\n",
    "*He picks a Deep Learning algorithm on a large data set and runs it on both GPUs 15 times, timing each run in hours. Results are given in the below lists GPU1 and GPU2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohh5XJ4ZbU3d"
   },
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yGkYI6EbU3i"
   },
   "outputs": [],
   "source": [
    "GPU1 = np.array([11,9,10,11,10,12,9,11,12,9,11,12,9,10,9])\n",
    "GPU2 = np.array([11,13,10,13,12,9,11,12,12,11,12,12,10,11,13])\n",
    "\n",
    "#Assumption: Both the datasets (GPU1 & GPU 2) are random, independent, parametric & normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L55jqmIXbU3m"
   },
   "source": [
    "Hint: You can import ttest function from scipy to perform t tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8fsIhPFbU3n"
   },
   "source": [
    "**First T test**\n",
    "\n",
    "*One sample t-test*\n",
    "\n",
    "Check if the mean of the GPU1 is equal to zero.\n",
    "- Null Hypothesis is that mean is equal to zero.\n",
    "- Alternate hypothesis is that it is not equal to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Since we dont know the standard deviation of population, we will use t statistic. One sample t -test on GPU1.\n",
    "\n",
    "    H0: Mu1=0\n",
    "    HA: Mu1!=0\n",
    "    \n",
    "Since alternate hypothesis says, it is not equal to zero. We need to consider two tailed one sample t test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgMSWwApbU3o",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we select α = 0.05\n",
      "\n",
      "Observed Sample Mean of GPU1: 10.333333333333334\n",
      "Standard Deviation of GPU1: 1.1751393027860062\n",
      "Standard Error: 0.3034196632775998\n",
      "Critical value: 0.6507704546500327 and -0.6507704546500326\n",
      "P value:  7.105427357601002e-15\n",
      "t Statistic:  34.056241516158195\n",
      "\n",
      "Using ttest_1samp function:\n",
      "t_statistic: 34.056241516158195  P value:  7.228892044970457e-15\n",
      "\n",
      "Since P value is very less than 5% of level of significance, hence we reject Null Hypothesis.\n",
      "That means mean is not equal to zero. \n"
     ]
    }
   ],
   "source": [
    "print('Here we select α = 0.05\\n')\n",
    "\n",
    "from scipy.stats import ttest_1samp \n",
    "Mu=0\n",
    "Xbar=np.mean(GPU1)\n",
    "print ('Observed Sample Mean of GPU1:',Xbar)\n",
    "S=np.std(GPU1,ddof=1)\n",
    "print ('Standard Deviation of GPU1:',S)\n",
    "n=15\n",
    "SE=S/np.sqrt(n)\n",
    "print ('Standard Error:', SE)\n",
    "print('Critical value:', stats.t.isf(0.025,df=n-1, loc=Mu,scale=SE) ,'and', stats.t.isf(.975,df=n-1,loc=Mu,scale=SE))\n",
    "P_value= 2*(1-stats.t.cdf(Xbar,df=n-1, loc=Mu,scale=SE))\n",
    "print('P value: ',P_value)\n",
    "t_stat=(Xbar-Mu)/SE\n",
    "print('t Statistic: ',t_stat)\n",
    "\n",
    "print('\\nUsing ttest_1samp function:')\n",
    "t_statistic, p_value = ttest_1samp(GPU1, 0)\n",
    "print('t_statistic:',t_statistic, ' P value: ',p_value)\n",
    "\n",
    "print('\\nSince P value is very less than 5% of level of significance, hence we reject Null Hypothesis.')\n",
    "print('That means mean is not equal to zero. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byu8iw46bU3v"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E65pzWcJbU3w"
   },
   "source": [
    "Given,\n",
    "\n",
    "Null Hypothesis : There is no significant difference between data sets\n",
    "\n",
    "Alternate Hypothesis : There is a significant difference\n",
    "\n",
    "*Do two-sample testing and check whether to reject Null Hypothesis or not.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-zpWvyXbU32"
   },
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UDDkuOtObU3x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of GPU1: 10.333333333333334\n",
      "Mean of GPU2: 11.466666666666667\n",
      "t_statistic: -2.627629513471839  P value:  0.013794282041452725\n",
      "\n",
      " Since P value is less than 5% of significance level hence it rejects the NULL Hypothesis. \n",
      "That means there is a significant difference between the datasets.\n"
     ]
    }
   ],
   "source": [
    "print ('Mean of GPU1:',np.mean(GPU1))\n",
    "print ('Mean of GPU2:',np.mean(GPU2))\n",
    "\n",
    "t_statistic,p_value = stats.ttest_ind(GPU1,GPU2)\n",
    "print ('t_statistic:',t_statistic, ' P value: ',p_value)\n",
    "print('\\n Since P value is less than 5% of significance level hence it rejects the NULL Hypothesis. ')\n",
    "print('That means there is a significant difference between the datasets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbXv5aZvbU33"
   },
   "source": [
    "## Question 3\n",
    "\n",
    "He is trying a third GPU - GPU3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkh_sQl4bU34"
   },
   "outputs": [],
   "source": [
    "GPU3 = np.array([9,10,9,11,10,13,12,9,12,12,13,12,13,10,11])\n",
    "\n",
    "#Assumption: Both the datasets (GPU1 & GPU 3) are random, independent, parametric & normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WoYNz3g7bU37"
   },
   "source": [
    "*Do two-sample testing and check whether there is significant differene between speeds of two GPUs GPU1 and GPU3.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4N11XArbU38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of GPU1: 10.333333333333334\n",
      "Mean of GPU3: 11.066666666666666\n",
      "Here we select α = 0.05\n",
      "\n",
      "t_statistic: -1.4988943759093303  P value:  0.14509210993138993\n",
      "\n",
      " Since P value which is 14.5% which is greater than 5% of significance level hence it fails to reject NULL Hypothesis.\n",
      "That means there is NO significant difference between the datasets.\n"
     ]
    }
   ],
   "source": [
    "print ('Mean of GPU1:',np.mean(GPU1))\n",
    "print ('Mean of GPU3:',np.mean(GPU3))\n",
    "print('Here we select α = 0.05\\n')\n",
    "\n",
    "t_statistic,p_value = stats.ttest_ind(GPU1,GPU3)\n",
    "print ('t_statistic:',t_statistic, ' P value: ',p_value)\n",
    "print('\\n Since P value which is 14.5% which is greater than 5% of significance level hence it fails to reject NULL Hypothesis.')\n",
    "print('That means there is NO significant difference between the datasets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyDFS4WZbU4A"
   },
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wknPzstFbU4B"
   },
   "source": [
    "## Question 4 \n",
    "\n",
    "If you need to compare more than two data sets at a time, an ANOVA is your best bet. \n",
    "\n",
    "*The results from three experiments with overlapping 95% confidence intervals are given below, and we want to confirm that the results for all three experiments are not significantly different.*\n",
    "\n",
    "But before conducting ANOVA, test equality of variances (using Levene's test) is satisfied or not. If not, then mention that we cannot depend on the result of ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGb0GeK8bU4C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "e1 = np.array([1.595440,1.419730,0.000000,0.000000])\n",
    "e2 = np.array([1.433800,2.079700,0.892139,2.384740])\n",
    "e3 = np.array([0.036930,0.938018,0.995956,1.006970])\n",
    "\n",
    "#Assumption: All the 3 datasets (e1,e2 & e3) are random, independent, parametric & normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xiYN6gVbU4G"
   },
   "source": [
    "Perform levene test on the data\n",
    "\n",
    "The Levene test tests the null hypothesis that all input samples are from populations with equal variances. Levene’s test is an alternative to Bartlett’s test bartlett in the case where there are significant deviations from normality.\n",
    "\n",
    "source: scipy.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2MlJTXgbU4H"
   },
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUJP_GGQbU4R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Hypothesis: All input samples are from populations with equal variances\n",
      "Alternate Hypothesis: All input samples are NOT from populations with equal variances\n",
      "\n",
      "Here we select α = 0.05\n",
      "\n",
      "statistic: 2.6741725711150446 P_value: 0.12259792666001798\n",
      "\n",
      "P value which is greater than 5% significance level, it fails to reject NULL Hypothesis. Means Null Hypothesis is true\n",
      "That means all input samples are from populations with equal variances.\n"
     ]
    }
   ],
   "source": [
    "print('Null Hypothesis: All input samples are from populations with equal variances')\n",
    "print('Alternate Hypothesis: All input samples are NOT from populations with equal variances\\n')\n",
    "print('Here we select α = 0.05\\n')\n",
    "\n",
    "statistic, p_value = stats.levene(e1,e2,e3) #Since samples are normally distributed, we are using mean here\n",
    "print('statistic:', statistic, 'P_value:' , p_value )\n",
    "print('\\nP value which is greater than 5% significance level, it fails to reject NULL Hypothesis. Means Null Hypothesis is true')\n",
    "print('That means all input samples are from populations with equal variances.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FigxGCQtbU4Y"
   },
   "source": [
    "## Question 5\n",
    "\n",
    "The one-way ANOVA tests the null hypothesis that two or more groups have the same population mean. The test is applied to samples from two or more groups, possibly with differing sizes.\n",
    "\n",
    "use stats.f_oneway() module to perform one-way ANOVA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3bPYPCbbU4Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Hypothesis: All groups have the same population mean\n",
      "Alternate Hypothesis: At least one group has different mean\n",
      "\n",
      "Here we select α = 0.05\n",
      "\n",
      "statistic: 2.51357622845924 P_value: 0.13574644501798466\n",
      "\n",
      "P value which is greater than 5% significance level, it fails to reject NULL Hypothesis. Means Null Hypothesis is true\n",
      "That means all groups have the same population mean.\n"
     ]
    }
   ],
   "source": [
    "print('Null Hypothesis: All groups have the same population mean')\n",
    "print('Alternate Hypothesis: At least one group has different mean\\n')\n",
    "print('Here we select α = 0.05\\n')\n",
    "\n",
    "statistic, p_value = stats.f_oneway(e1,e2,e3)\n",
    "print('statistic:', statistic, 'P_value:' , p_value )\n",
    "print('\\nP value which is greater than 5% significance level, it fails to reject NULL Hypothesis. Means Null Hypothesis is true')\n",
    "print('That means all groups have the same population mean.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrMK1qb7bU4j"
   },
   "source": [
    "## Question 6\n",
    "\n",
    "*In one or two sentences explain about **TypeI** and **TypeII** errors.*\n",
    "\n",
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H08OGwdIbU4k"
   },
   "source": [
    "Type 1 and type II errors are mistakes in testing a hypothesis. A type I error occurs when the results of research show that a difference exists but in truth there is no difference; so, the null hypothesis H0 is wrongly rejected when it is true. A type II error occurs when the null hypothesis is accepted, but the alternative is true; that is, the null hypothesis, is not rejected when it is false. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hm7v3pcIbU4m"
   },
   "source": [
    "## Question 7 \n",
    "\n",
    "You are a manager of a chinese restaurant. You want to determine whether the waiting time to place an order has changed in the past month from its previous population mean value of 4.5 minutes. \n",
    "State the null and alternative hypothesis.\n",
    "\n",
    "#### Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbbaU2I4bU4n"
   },
   "source": [
    "As a manager, I would want to have waiting time lesser compared to earlier to attract customers or to increase customer satisfaction. SO as a quality check I would like to know if waiting time has been increased or not. \n",
    "   \n",
    "   Null Hypothesis : waiting time after <= waiting time before  \n",
    "Alternate Hypothesis: waiting time after > waiting time before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SGpq-dKbU4r"
   },
   "source": [
    "## Chi square test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlxmIu_rdgpc"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8J3V015PbU4s"
   },
   "source": [
    "Let's create a small dataset for dice rolls of four players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrO5BbIEbU4t"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "d1 = [5, 8, 3, 8]\n",
    "d2 = [9, 6, 8, 5]\n",
    "d3 = [8, 12, 7, 2]\n",
    "d4 = [4, 16, 7, 3]\n",
    "d5 = [3, 9, 6, 5]\n",
    "d6 = [7, 2, 5, 7]\n",
    "\n",
    "dice = np.array([d1, d2, d3, d4, d5, d6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uF7GRMChbU4x"
   },
   "source": [
    "run the test using SciPy Stats library\n",
    "\n",
    "Depending on the test, we are generally looking for a threshold at either 0.05 or 0.01. Our test is significant (i.e. we reject the null hypothesis) if we get a p-value below our threshold.\n",
    "\n",
    "For our purposes, we’ll use 0.01 as the threshold.\n",
    "\n",
    "use stats.chi2_contingency() module \n",
    "\n",
    "This function computes the chi-square statistic and p-value for the hypothesis test of independence of the observed frequencies in the contingency table\n",
    "\n",
    "Print the following:\n",
    "\n",
    "- chi2 stat\n",
    "- p-value\n",
    "- degree of freedom\n",
    "- contingency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqaTIKmgbU4y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 stat:  23.315671914716496\n",
      "p-value:  0.07766367301496693\n",
      "Degree of Fredom: 15\n",
      "Contingency: \n",
      " [[ 5.57419355  8.20645161  5.57419355  4.64516129]\n",
      " [ 6.50322581  9.57419355  6.50322581  5.41935484]\n",
      " [ 6.73548387  9.91612903  6.73548387  5.61290323]\n",
      " [ 6.96774194 10.25806452  6.96774194  5.80645161]\n",
      " [ 5.34193548  7.86451613  5.34193548  4.4516129 ]\n",
      " [ 4.87741935  7.18064516  4.87741935  4.06451613]]\n",
      "\n",
      "P-value which is .077 which is greater than level of significance 0.01 hence we fail to reject the Null Hypothesis.\n"
     ]
    }
   ],
   "source": [
    "chi2,P,DOF,Contingency = stats.chi2_contingency(dice)\n",
    "print('Chi2 stat: ' , chi2)\n",
    "print('p-value: ', P)\n",
    "print('Degree of Fredom:', DOF)\n",
    "print('Contingency: \\n' ,Contingency)\n",
    "print('\\nP-value which is .077 which is greater than level of significance 0.01 hence we fail to reject the Null Hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzyfaNoabU42"
   },
   "source": [
    "## Question 9\n",
    "\n",
    "### Z-test\n",
    "\n",
    "Get zscore on the above dice data using stats.zscore module from scipy. Convert zscore values to p-value and take mean of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sd5xPCuRbU43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zscore of d1: [-0.40824829  0.81649658 -1.22474487  0.81649658]\n",
      "Zscore of d2: [ 1.09544512 -0.54772256  0.54772256 -1.09544512]\n",
      "Zscore of d3: [ 0.1823492   1.15487828 -0.06078307 -1.27644442]\n",
      "Zscore of d4: [-0.59160798  1.43676223 -0.08451543 -0.76063883]\n",
      "Zscore of d5: [-1.1  1.3  0.1 -0.3]\n",
      "Zscore of d6: [ 0.7406129  -1.37542395 -0.10580184  0.7406129 ]\n",
      "\n",
      "Assuming it is 1 tailed left tailed test\n",
      "\n",
      "With Zscores, it is sampled distribution which has Mu =0 and Sigma =1\n",
      "\n",
      "P_value of d1: [0.3415457  0.79289191 0.11033568 0.79289191]\n",
      "P_value of d1: [0.86333916 0.29194121 0.70805879 0.13666084]\n",
      "P_value of d1: [0.57234566 0.87592986 0.47576599 0.10089923]\n",
      "P_value of d1: [0.27705657 0.92460722 0.46632332 0.22343641]\n",
      "P_value of d1: [0.13566606 0.90319952 0.53982784 0.38208858]\n",
      "P_value of d1: [0.77053591 0.08450002 0.45786979 0.77053591]\n",
      "\n",
      "Mean of p_values of d1:  0.5094163004680505\n",
      "Mean of p_values of d2:  0.5\n",
      "Mean of p_values of d3:  0.5062351845851735\n",
      "Mean of p_values of d4:  0.4728558780897726\n",
      "Mean of p_values of d5:  0.49019549786221217\n",
      "Mean of p_values of d6:  0.5208604063207791\n"
     ]
    }
   ],
   "source": [
    "Z_d1=stats.zscore(d1,ddof=1)\n",
    "print('Zscore of d1:', Z_d1)\n",
    "Z_d2=stats.zscore(d2,ddof=1)\n",
    "print('Zscore of d2:', Z_d2)\n",
    "Z_d3=stats.zscore(d3,ddof=1)\n",
    "print('Zscore of d3:', Z_d3)\n",
    "Z_d4=stats.zscore(d4,ddof=1)\n",
    "print('Zscore of d4:', Z_d4)\n",
    "Z_d5=stats.zscore(d5,ddof=1)\n",
    "print('Zscore of d5:', Z_d5)\n",
    "Z_d6=stats.zscore(d6,ddof=1)\n",
    "print('Zscore of d6:', Z_d6)\n",
    "\n",
    "print('\\nAssuming it is 1 tailed left tailed test\\n')\n",
    "print('With Zscores, it is sampled distribution which has Mu =0 and Sigma =1\\n')\n",
    "\n",
    "P_d1=stats.norm.cdf(Z_d1,loc=0,scale=1)\n",
    "print('P_value of d1:', P_d1)\n",
    "P_d2=stats.norm.cdf(Z_d2,loc=0,scale=1)\n",
    "print('P_value of d1:', P_d2)\n",
    "P_d3=stats.norm.cdf(Z_d3,loc=0,scale=1)\n",
    "print('P_value of d1:', P_d3)\n",
    "P_d4=stats.norm.cdf(Z_d4,loc=0,scale=1)\n",
    "print('P_value of d1:', P_d4)\n",
    "P_d5=stats.norm.cdf(Z_d5,loc=0,scale=1)\n",
    "print('P_value of d1:', P_d5)\n",
    "P_d6=stats.norm.cdf(Z_d6,loc=0,scale=1)\n",
    "print('P_value of d1:', P_d6)\n",
    "\n",
    "print('\\nMean of p_values of d1: ', np.mean(P_d1))\n",
    "print('Mean of p_values of d2: ', np.mean(P_d2))\n",
    "print('Mean of p_values of d3: ', np.mean(P_d3))\n",
    "print('Mean of p_values of d4: ', np.mean(P_d4))\n",
    "print('Mean of p_values of d5: ', np.mean(P_d5))\n",
    "print('Mean of p_values of d6: ', np.mean(P_d6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyoFUxf5bU47"
   },
   "source": [
    "## Question 10\n",
    "\n",
    "A Paired sample t-test compares means from the same group at different times.\n",
    "\n",
    "The basic two sample t-test is designed for testing differences between independent groups. \n",
    "In some cases, you might be interested in testing differences between samples of the same group at different points in time. \n",
    "We can conduct a paired t-test using the scipy function stats.ttest_rel(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwVmQ1gRbU48"
   },
   "outputs": [],
   "source": [
    "before= stats.norm.rvs(scale=30, loc=100, size=500) ## Creates a normal distribution with a mean value of 100 and std of 30\n",
    "after = before + stats.norm.rvs(scale=5, loc=-1.25, size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rB_os5FjbU4_"
   },
   "source": [
    "Test whether a weight-loss drug works by checking the weights of the same group patients before and after treatment using above data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Hypothesis: Weight remains same before and after weight loss drug treatment means Mu of difference is zero\n",
      "Alternate Hypothesis: Weight does not remain same before and after weight loss drug treatment means Mu of difference is not equal to zero\n",
      "\n",
      "Here we select α = 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Null Hypothesis: Weight remains same before and after weight loss drug treatment means Mu of difference is zero')\n",
    "print('Alternate Hypothesis: Weight does not remain same before and after weight loss drug treatment means Mu of difference is not equal to zero\\n')\n",
    "print('Here we select α = 0.05\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic: -6.0022637654511914 P_value: 3.746148844127565e-09\n",
      "\n",
      "Here P value is less than 5% significance level, it rejects the NULL Hypothesis. Means Alternate Hypothesis is true.\n",
      "That means Weight does not remain same before and after weight loss drug treatment that proves that weight loss drug works.\n"
     ]
    }
   ],
   "source": [
    "statistic, p_value = stats.ttest_rel(after,before)\n",
    "print('statistic:', statistic, 'P_value:' , p_value )\n",
    "print('\\nHere P value is less than 5% significance level, it rejects the NULL Hypothesis. Means Alternate Hypothesis is true.')\n",
    "print('That means Weight does not remain same before and after weight loss drug treatment that proves that weight loss drug works.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R2_external-lab_hypothesis_testing_questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
