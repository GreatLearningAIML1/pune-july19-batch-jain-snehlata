{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_Internal_Lab_UpdatedTF2_Prices_Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84Q8JfvaeZZ6"
      },
      "source": [
        "## Linear Classifier in TensorFlow \n",
        "Using Low Level API in Eager Execution mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e96WQ2zQEIjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "155b3436-9b2e-4814-d543-441c2149d563"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3644acb-fd99-42f6-8823-6612b8f87bb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiObW4V4SIOz",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/gdrive/My Drive/Colab Notebooks/Residency6_internallab/prices.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "efa6ac5e-182c-4433-c285-e4622e7bfe06"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date symbol        open  ...         low        high     volume\n",
              "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
              "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
              "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
              "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
              "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data.drop(columns=['date','symbol'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "8994f649-a63e-4df8-a57a-c6a5129aa9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
        "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {}
      },
      "source": [
        "data=data.iloc[:1000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCJBCf1HyjeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ba4a169-b889-4d27-e7a5-1cc2c70768de"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTUuEaiGyn5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['volume']=data['volume']/1000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3aqu1Uyy2Lu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "52af6d42-e523-4b6b-ca1c-87fc302d694e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2.1636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2.3864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2.4895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2.0063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1.4086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high  volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2.1636\n",
              "1  125.239998  119.980003  119.940002  125.540001  2.3864\n",
              "2  116.379997  114.949997  114.930000  119.739998  2.4895\n",
              "3  115.480003  116.620003  113.500000  117.440002  2.0063\n",
              "4  117.010002  114.970001  114.089996  117.330002  1.4086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4LE4U8lTdQJq",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB7AONdDzYbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=data.iloc[:,:-1]\n",
        "y=data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQrQ7s0zf8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5d8ec868-1a2f-4a3a-e633-02770bc557ba"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high\n",
              "0  123.430000  125.839996  122.309998  126.250000\n",
              "1  125.239998  119.980003  119.940002  125.540001\n",
              "2  116.379997  114.949997  114.930000  119.739998\n",
              "3  115.480003  116.620003  113.500000  117.440002\n",
              "4  117.010002  114.970001  114.089996  117.330002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W07K7mF7zxhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a014870-d91d-4171-bcee-8b855345f2c3"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of96hwXRztni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "04ea3add-7601-4cd3-a07e-29b3088efa5a"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2.1636\n",
              "1    2.3864\n",
              "2    2.4895\n",
              "3    2.0063\n",
              "4    1.4086\n",
              "Name: volume, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eKjhEcMz0U7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2017ed9-01ca-4aec-fdd1-5155cb814d5c"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5sFOW76zORh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDzx71d80EK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "218ba69e-c996-4fcc-9362-94d41f8423f5"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(700, 4)\n",
            "(700,)\n",
            "(300, 4)\n",
            "(300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYK-aUuLbrz2"
      },
      "source": [
        "#### Convert Training and Test Data to numpy float32 arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ao-S0tQGcncz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f76165ca-46c4-48dc-8b21-2cb436a8ad59"
      },
      "source": [
        "X_test.dtypes"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open     float64\n",
              "close    float64\n",
              "low      float64\n",
              "high     float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bey75dAB0hxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train=np.array(X_train).astype('float32')\n",
        "X_test=np.array(X_test).astype('float32')\n",
        "y_train=np.array(y_train).astype('float32')\n",
        "y_test=np.array(y_test).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkpBzad_1qlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e3221ece-b119-4b04-a318-ad3da7e91b30"
      },
      "source": [
        "print(X_train.dtype)\n",
        "print(X_test.dtype)\n",
        "print(y_train.dtype)\n",
        "print(y_test.dtype)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35hSe73s5j_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tenserflow needs output variable should always be in column vector. reshape converts it into row vector to column vector. \n",
        "y_train=y_train.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNIZJH-p6qt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d6fcc49-6f18-4227-a331-86ae429f8907"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dm-_PbV6ueQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83MgHC1t6upH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "im1ZegbDdKgv"
      },
      "source": [
        "### Normalize the data\n",
        "You can use Normalizer from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L_btRfh2DEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm=Normalizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2WSJQMp2DPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = norm.fit_transform(X_train)\n",
        "X_test = norm.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the Model in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Input-hidden Layer) --- 4 features with 5 nueron\n",
        "w1 = tf.zeros(shape=(4,5))\n",
        "b1 = tf.zeros(shape=(5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsnSxceC7LJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1a200e97-439a-43c9-d5de-92175ab9b503"
      },
      "source": [
        "w1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=2, shape=(4, 5), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAr43COb7N40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00107236-0b76-46ce-bfda-2287bfbc9fcf"
      },
      "source": [
        "b1"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=5, shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6rGb1F-D5-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (hidden - output Layer) --- 4 features with 5 nueron\n",
        "w2= tf.zeros(shape=(5,1))\n",
        "b2 = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PioTMqHCD6IE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0195dbf0-6cbf-490c-d8af-32d3d8ec6d9c"
      },
      "source": [
        "w2"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=4082, shape=(5, 1), dtype=float32, numpy=\n",
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC8_lYXfD6Ra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04b2d25d-c032-4e1d-d440-d1f0840926fe"
      },
      "source": [
        "b2"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=4085, shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "2.Define a function to calculate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def prediction(x, w1, b1,w2,b2):\n",
        "    y_out = tf.add(tf.matmul(x, w1), b1)\n",
        "    y_pred = tf.add(tf.matmul(y_out, w2), b2)\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "3.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def loss(y_actual, y_predicted):\n",
        "    diff = y_actual - y_predicted\n",
        "    sqr = tf.square(diff)\n",
        "    avg = tf.reduce_mean(sqr)\n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "4.Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "def train(x, y_actual, w1, b1, w2, b2, learning_rate=0.01):\n",
        "    \n",
        "    # Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "        t.watch([w1,b1,w2,b2])\n",
        "        current_prediction = prediction(x, w1, b1, w2, b2)\n",
        "        current_loss = loss(y_actual, current_prediction)\n",
        "    \n",
        "    # Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw1,db1,dw2,db2 = t.gradient(current_loss,[w1, b1, w2, b2])\n",
        "    \n",
        "    #Update Weights at output layer\n",
        "    w2 = w2 - learning_rate*dw2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    \n",
        "     #Update Weights at hidden layer\n",
        "    w1 = w1 - learning_rate*dw1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    \n",
        "    return w1, b1,w2,b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Train the model for 100 epochs \n",
        "1. Observe the training loss at every iteration\n",
        "2. Observe Train loss at every 5th iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a24fd7df-999f-4465-c1df-1f222fcf7626"
      },
      "source": [
        "for i in range(100):    \n",
        "    w1, b1,w2,b2 = train(X_train, y_train, w1, b1,w2,b2)\n",
        "    if i%5 ==0:\n",
        "      print('Current Training Loss on iteration', i, loss(y_train, prediction(X_train, w1, b1,w2,b2)).numpy())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Current Training Loss on iteration', 0, 273.9678)\n",
            "('Current Training Loss on iteration', 5, 273.95438)\n",
            "('Current Training Loss on iteration', 10, 273.9543)\n",
            "('Current Training Loss on iteration', 15, 273.95428)\n",
            "('Current Training Loss on iteration', 20, 273.95425)\n",
            "('Current Training Loss on iteration', 25, 273.9542)\n",
            "('Current Training Loss on iteration', 30, 273.95416)\n",
            "('Current Training Loss on iteration', 35, 273.95413)\n",
            "('Current Training Loss on iteration', 40, 273.95407)\n",
            "('Current Training Loss on iteration', 45, 273.954)\n",
            "('Current Training Loss on iteration', 50, 273.95398)\n",
            "('Current Training Loss on iteration', 55, 273.95392)\n",
            "('Current Training Loss on iteration', 60, 273.9539)\n",
            "('Current Training Loss on iteration', 65, 273.95383)\n",
            "('Current Training Loss on iteration', 70, 273.9538)\n",
            "('Current Training Loss on iteration', 75, 273.95374)\n",
            "('Current Training Loss on iteration', 80, 273.95367)\n",
            "('Current Training Loss on iteration', 85, 273.95367)\n",
            "('Current Training Loss on iteration', 90, 273.9536)\n",
            "('Current Training Loss on iteration', 95, 273.95358)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0347c2ca-72b0-4c0b-f451-a4648144b256"
      },
      "source": [
        "w1.numpy()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.761003  , 0.761003  , 0.761003  , 0.761003  , 0.761003  ],\n",
              "       [0.78630155, 0.78630155, 0.78630155, 0.78630155, 0.78630155],\n",
              "       [0.75765836, 0.75765836, 0.75765836, 0.75765836, 0.75765836],\n",
              "       [0.7934293 , 0.7934293 , 0.7934293 , 0.7934293 , 0.7934293 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1b556ed-ce51-446a-a505-216eee3d7219"
      },
      "source": [
        "b1.numpy()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.549563, 1.549563, 1.549563, 1.549563, 1.549563], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uRths8GHTGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f0cc140d-f081-4fdb-9561-4f5f9593aba9"
      },
      "source": [
        "w2.numpy()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3546951],\n",
              "       [0.3546951],\n",
              "       [0.3546951],\n",
              "       [0.3546951],\n",
              "       [0.3546951]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "refGv6xVHsnb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e3a87d2-87f0-4754-c7ee-59037bab2e4b"
      },
      "source": [
        "b2.numpy()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11448701], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERq9GOKKciho"
      },
      "source": [
        "### Model Prediction on 1st Examples in Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKGvUWahcihp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb41f45a-7ee2-4c2d-ed7b-7233db7c87dc"
      },
      "source": [
        "pred=prediction(X_test[:1,:],w1,b1,w2,b2)  ## for test data we only apply foerard pass only. \n",
        "pred"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=9441, shape=(1, 1), dtype=float32, numpy=array([[5.610027]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLNM46qDC472",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "477bdaed-3b3d-491e-c459-c6b5ad5c1be6"
      },
      "source": [
        "print('Current Testing Loss on 1st Example', loss(y_test, prediction(X_test[:1,:],w1,b1,w2,b2)).numpy())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Current Testing Loss on 1st Example', 57.884544)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmvgoAi1IB-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt7NxXEzIDnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lE8gObzIDyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib9yvWw3ID8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "## Classification using tf.Keras\n",
        "\n",
        "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O0g6lorycihf"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xFvb5sRcihg",
        "colab": {}
      },
      "source": [
        "iris = pd.read_csv('/gdrive/My Drive/Colab Notebooks/Residency6_internallab/11_Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAB--Qdwcihm"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJr5dYnocihm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "afca8445-504b-4318-dae1-ef575fcaa923"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5vMWPpQJE0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris_encoded=pd.get_dummies(iris,prefix=['Species'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEk0iLkzJ32v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f115610a-e9c4-4707-dd50-7f05bab7f8e4"
      },
      "source": [
        "iris_encoded.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species_Iris-setosa</th>\n",
              "      <th>Species_Iris-versicolor</th>\n",
              "      <th>Species_Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  ...  Species_Iris-versicolor  Species_Iris-virginica\n",
              "0   1            5.1  ...                        0                       0\n",
              "1   2            4.9  ...                        0                       0\n",
              "2   3            4.7  ...                        0                       0\n",
              "3   4            4.6  ...                        0                       0\n",
              "4   5            5.0  ...                        0                       0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D95nY5ILcihj"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyMQoLMucihj",
        "colab": {}
      },
      "source": [
        "X=iris_encoded.iloc[:,:-3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG9m4mmpLBra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d09c0ff3-f928-48cd-9b82-fac2a36df5d7"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "0   1            5.1           3.5            1.4           0.2\n",
              "1   2            4.9           3.0            1.4           0.2\n",
              "2   3            4.7           3.2            1.3           0.2\n",
              "3   4            4.6           3.1            1.5           0.2\n",
              "4   5            5.0           3.6            1.4           0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awFi6MNlLGvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=iris_encoded.iloc[:,-3:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18sGOjULMju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e4f62649-9ca3-4af4-dade-6be90d3b496c"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species_Iris-setosa</th>\n",
              "      <th>Species_Iris-versicolor</th>\n",
              "      <th>Species_Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Species_Iris-setosa  Species_Iris-versicolor  Species_Iris-virginica\n",
              "0                    1                        0                       0\n",
              "1                    1                        0                       0\n",
              "2                    1                        0                       0\n",
              "3                    1                        0                       0\n",
              "4                    1                        0                       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqAVM8yPPdK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe3-MgCIPgq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=y.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b22qpC5xcihr"
      },
      "source": [
        "###  Building Model in tf.keras\n",
        "\n",
        "Build a Linear Classifier model  <br>\n",
        "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
        "2. Apply Softmax on Dense Layer outputs <br>\n",
        "3. Use SGD as Optimizer\n",
        "4. Use categorical_crossentropy as loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hov_UFnUciht",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 3 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(3, input_shape=(4,), activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC2C__s9MdYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5FdzqIKcihw"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4qLEdHPscihx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c3a1cde-0ee0-4984-b274-c593b097423d"
      },
      "source": [
        "model.fit(X,y, epochs=100,\n",
        "          batch_size = X.shape[0])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 150 samples\n",
            "Epoch 1/100\n",
            "150/150 [==============================] - 0s 61us/sample - loss: 0.7778 - accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 0s 37us/sample - loss: 0.7727 - accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.7677 - accuracy: 0.6667\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.7628 - accuracy: 0.6733\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 0.7580 - accuracy: 0.6733\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.7533 - accuracy: 0.6800\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 0s 20us/sample - loss: 0.7486 - accuracy: 0.6933\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 0.7441 - accuracy: 0.7000\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.7396 - accuracy: 0.7067\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 0.7352 - accuracy: 0.7133\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 0.7308 - accuracy: 0.7133\n",
            "Epoch 12/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.7266 - accuracy: 0.7133\n",
            "Epoch 13/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 0.7224 - accuracy: 0.7267\n",
            "Epoch 14/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 0.7183 - accuracy: 0.7267\n",
            "Epoch 15/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 0.7142 - accuracy: 0.7267\n",
            "Epoch 16/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 0.7102 - accuracy: 0.7267\n",
            "Epoch 17/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.7063 - accuracy: 0.7267\n",
            "Epoch 18/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 0.7024 - accuracy: 0.7267\n",
            "Epoch 19/100\n",
            "150/150 [==============================] - 0s 38us/sample - loss: 0.6986 - accuracy: 0.7267\n",
            "Epoch 20/100\n",
            "150/150 [==============================] - 0s 40us/sample - loss: 0.6948 - accuracy: 0.7267\n",
            "Epoch 21/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 0.6911 - accuracy: 0.7400\n",
            "Epoch 22/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 0.6875 - accuracy: 0.7400\n",
            "Epoch 23/100\n",
            "150/150 [==============================] - 0s 15us/sample - loss: 0.6839 - accuracy: 0.7467\n",
            "Epoch 24/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.6804 - accuracy: 0.7467\n",
            "Epoch 25/100\n",
            "150/150 [==============================] - 0s 23us/sample - loss: 0.6769 - accuracy: 0.7467\n",
            "Epoch 26/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.6735 - accuracy: 0.7533\n",
            "Epoch 27/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.6701 - accuracy: 0.7533\n",
            "Epoch 28/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.6668 - accuracy: 0.7533\n",
            "Epoch 29/100\n",
            "150/150 [==============================] - 0s 39us/sample - loss: 0.6635 - accuracy: 0.7533\n",
            "Epoch 30/100\n",
            "150/150 [==============================] - 0s 33us/sample - loss: 0.6602 - accuracy: 0.7533\n",
            "Epoch 31/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 0.6571 - accuracy: 0.7533\n",
            "Epoch 32/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.6539 - accuracy: 0.7600\n",
            "Epoch 33/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 0.6508 - accuracy: 0.7600\n",
            "Epoch 34/100\n",
            "150/150 [==============================] - 0s 38us/sample - loss: 0.6477 - accuracy: 0.7600\n",
            "Epoch 35/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 0.6447 - accuracy: 0.7600\n",
            "Epoch 36/100\n",
            "150/150 [==============================] - 0s 40us/sample - loss: 0.6417 - accuracy: 0.7600\n",
            "Epoch 37/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.6388 - accuracy: 0.7600\n",
            "Epoch 38/100\n",
            "150/150 [==============================] - 0s 33us/sample - loss: 0.6359 - accuracy: 0.7600\n",
            "Epoch 39/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.6330 - accuracy: 0.7600\n",
            "Epoch 40/100\n",
            "150/150 [==============================] - 0s 35us/sample - loss: 0.6302 - accuracy: 0.7600\n",
            "Epoch 41/100\n",
            "150/150 [==============================] - 0s 36us/sample - loss: 0.6274 - accuracy: 0.7667\n",
            "Epoch 42/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 0.6246 - accuracy: 0.7667\n",
            "Epoch 43/100\n",
            "150/150 [==============================] - 0s 21us/sample - loss: 0.6219 - accuracy: 0.7667\n",
            "Epoch 44/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 0.6192 - accuracy: 0.7733\n",
            "Epoch 45/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 0.6166 - accuracy: 0.7733\n",
            "Epoch 46/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 0.6140 - accuracy: 0.7733\n",
            "Epoch 47/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 0.6114 - accuracy: 0.7733\n",
            "Epoch 48/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.6088 - accuracy: 0.7800\n",
            "Epoch 49/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 0.6063 - accuracy: 0.7800\n",
            "Epoch 50/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.6038 - accuracy: 0.7867\n",
            "Epoch 51/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 0.6013 - accuracy: 0.7867\n",
            "Epoch 52/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 0.5989 - accuracy: 0.7867\n",
            "Epoch 53/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.5964 - accuracy: 0.7867\n",
            "Epoch 54/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 0.5941 - accuracy: 0.7867\n",
            "Epoch 55/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 0.5917 - accuracy: 0.7933\n",
            "Epoch 56/100\n",
            "150/150 [==============================] - 0s 21us/sample - loss: 0.5894 - accuracy: 0.7933\n",
            "Epoch 57/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.5871 - accuracy: 0.7933\n",
            "Epoch 58/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 0.5848 - accuracy: 0.7933\n",
            "Epoch 59/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 0.5825 - accuracy: 0.7933\n",
            "Epoch 60/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5803 - accuracy: 0.7933\n",
            "Epoch 61/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.5781 - accuracy: 0.7933\n",
            "Epoch 62/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5759 - accuracy: 0.7933\n",
            "Epoch 63/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.5738 - accuracy: 0.8000\n",
            "Epoch 64/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 0.5716 - accuracy: 0.7933\n",
            "Epoch 65/100\n",
            "150/150 [==============================] - 0s 21us/sample - loss: 0.5695 - accuracy: 0.7933\n",
            "Epoch 66/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.5674 - accuracy: 0.7933\n",
            "Epoch 67/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5653 - accuracy: 0.8067\n",
            "Epoch 68/100\n",
            "150/150 [==============================] - 0s 20us/sample - loss: 0.5633 - accuracy: 0.8067\n",
            "Epoch 69/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 0.5613 - accuracy: 0.8067\n",
            "Epoch 70/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5593 - accuracy: 0.8067\n",
            "Epoch 71/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 0.5573 - accuracy: 0.8067\n",
            "Epoch 72/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.5553 - accuracy: 0.8067\n",
            "Epoch 73/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5534 - accuracy: 0.8067\n",
            "Epoch 74/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5514 - accuracy: 0.8000\n",
            "Epoch 75/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 0.5495 - accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5476 - accuracy: 0.8067\n",
            "Epoch 77/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.5458 - accuracy: 0.8067\n",
            "Epoch 78/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.5439 - accuracy: 0.8067\n",
            "Epoch 79/100\n",
            "150/150 [==============================] - 0s 38us/sample - loss: 0.5421 - accuracy: 0.8067\n",
            "Epoch 80/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.5402 - accuracy: 0.8067\n",
            "Epoch 81/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.5384 - accuracy: 0.8067\n",
            "Epoch 82/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.5366 - accuracy: 0.8067\n",
            "Epoch 83/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.5349 - accuracy: 0.8067\n",
            "Epoch 84/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5331 - accuracy: 0.8067\n",
            "Epoch 85/100\n",
            "150/150 [==============================] - 0s 20us/sample - loss: 0.5314 - accuracy: 0.8133\n",
            "Epoch 86/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.5297 - accuracy: 0.8133\n",
            "Epoch 87/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 0.5280 - accuracy: 0.8133\n",
            "Epoch 88/100\n",
            "150/150 [==============================] - 0s 20us/sample - loss: 0.5263 - accuracy: 0.8200\n",
            "Epoch 89/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 0.5246 - accuracy: 0.8200\n",
            "Epoch 90/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 0.5229 - accuracy: 0.8200\n",
            "Epoch 91/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.5213 - accuracy: 0.8200\n",
            "Epoch 92/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 0.5196 - accuracy: 0.8200\n",
            "Epoch 93/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 0.5180 - accuracy: 0.8200\n",
            "Epoch 94/100\n",
            "150/150 [==============================] - 0s 35us/sample - loss: 0.5164 - accuracy: 0.8200\n",
            "Epoch 95/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 0.5148 - accuracy: 0.8200\n",
            "Epoch 96/100\n",
            "150/150 [==============================] - 0s 42us/sample - loss: 0.5132 - accuracy: 0.8200\n",
            "Epoch 97/100\n",
            "150/150 [==============================] - 0s 38us/sample - loss: 0.5117 - accuracy: 0.8200\n",
            "Epoch 98/100\n",
            "150/150 [==============================] - 0s 37us/sample - loss: 0.5101 - accuracy: 0.8200\n",
            "Epoch 99/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 0.5086 - accuracy: 0.8200\n",
            "Epoch 100/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 0.5070 - accuracy: 0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56b037bf10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-SgSSdRcih5"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoG1ZWvgQ6Vg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1481b7a3-292c-4e9a-92e6-bee5f5e8a1eb"
      },
      "source": [
        "model.predict(X,batch_size=X.shape[0])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.78499854, 0.18064202, 0.03435946],\n",
              "       [0.70962715, 0.24371615, 0.04665675],\n",
              "       [0.7851802 , 0.17725205, 0.03756767],\n",
              "       [0.78402954, 0.17580193, 0.04016854],\n",
              "       [0.8051385 , 0.16052826, 0.03433321],\n",
              "       [0.7993704 , 0.16338846, 0.03724113],\n",
              "       [0.8252056 , 0.13898225, 0.03581207],\n",
              "       [0.75521433, 0.20038792, 0.04439778],\n",
              "       [0.75457364, 0.19591564, 0.04951067],\n",
              "       [0.6957904 , 0.2500555 , 0.05415408],\n",
              "       [0.728757  , 0.22390968, 0.0473333 ],\n",
              "       [0.77715033, 0.17698646, 0.04586327],\n",
              "       [0.67367023, 0.26587737, 0.06045235],\n",
              "       [0.76323   , 0.18775176, 0.04901822],\n",
              "       [0.68525594, 0.26376516, 0.05097885],\n",
              "       [0.79856145, 0.1610343 , 0.04040416],\n",
              "       [0.7404843 , 0.20732018, 0.05219548],\n",
              "       [0.70662606, 0.23262447, 0.06074944],\n",
              "       [0.6526626 , 0.2805646 , 0.06677276],\n",
              "       [0.76717913, 0.18062696, 0.05219395],\n",
              "       [0.6038751 , 0.31791237, 0.07821254],\n",
              "       [0.73625654, 0.20191494, 0.06182854],\n",
              "       [0.7892514 , 0.16140029, 0.04934835],\n",
              "       [0.6320503 , 0.27848542, 0.08946429],\n",
              "       [0.72363144, 0.20637822, 0.06999031],\n",
              "       [0.55639994, 0.34573153, 0.09786852],\n",
              "       [0.6607546 , 0.254273  , 0.08497233],\n",
              "       [0.631326  , 0.28590375, 0.0827703 ],\n",
              "       [0.59429985, 0.3160119 , 0.08968828],\n",
              "       [0.6595152 , 0.2526127 , 0.08787209],\n",
              "       [0.60313934, 0.29718262, 0.09967802],\n",
              "       [0.52953845, 0.35984135, 0.11062016],\n",
              "       [0.7512745 , 0.18671553, 0.06200998],\n",
              "       [0.7063005 , 0.2233785 , 0.07032095],\n",
              "       [0.54984033, 0.33987948, 0.11028024],\n",
              "       [0.53656685, 0.35163757, 0.11179565],\n",
              "       [0.49357173, 0.39292666, 0.11350159],\n",
              "       [0.5306719 , 0.35008866, 0.11923952],\n",
              "       [0.61194783, 0.27537036, 0.11268181],\n",
              "       [0.5537611 , 0.32847372, 0.11776515],\n",
              "       [0.5932981 , 0.29361847, 0.11308352],\n",
              "       [0.3702818 , 0.45461437, 0.17510384],\n",
              "       [0.64087194, 0.24748409, 0.11164398],\n",
              "       [0.5820166 , 0.28119707, 0.13678634],\n",
              "       [0.64405376, 0.23915224, 0.11679408],\n",
              "       [0.4708711 , 0.37217444, 0.15695447],\n",
              "       [0.62390697, 0.2616787 , 0.11441434],\n",
              "       [0.56470805, 0.29733604, 0.137956  ],\n",
              "       [0.53142273, 0.33345586, 0.1351214 ],\n",
              "       [0.48126855, 0.36491403, 0.15381749],\n",
              "       [0.14018607, 0.5221608 , 0.3376531 ],\n",
              "       [0.2140837 , 0.4320954 , 0.3538209 ],\n",
              "       [0.13325082, 0.49844226, 0.368307  ],\n",
              "       [0.17376299, 0.44851622, 0.37772074],\n",
              "       [0.1277216 , 0.48684528, 0.38543317],\n",
              "       [0.23231284, 0.38992378, 0.37776336],\n",
              "       [0.2257448 , 0.38424814, 0.39000705],\n",
              "       [0.26008388, 0.3952682 , 0.34464788],\n",
              "       [0.11891832, 0.50025576, 0.38082597],\n",
              "       [0.26262793, 0.3462429 , 0.39112923],\n",
              "       [0.16032797, 0.45150593, 0.38816607],\n",
              "       [0.20044157, 0.38956603, 0.40999243],\n",
              "       [0.08468165, 0.5368861 , 0.37843227],\n",
              "       [0.15672602, 0.41096023, 0.43231377],\n",
              "       [0.20715432, 0.39841005, 0.39443558],\n",
              "       [0.10883256, 0.48117352, 0.40999395],\n",
              "       [0.22460002, 0.3301036 , 0.44529644],\n",
              "       [0.14637719, 0.44703546, 0.4065873 ],\n",
              "       [0.06100096, 0.47342953, 0.4655695 ],\n",
              "       [0.13130844, 0.4387163 , 0.4299753 ],\n",
              "       [0.19287401, 0.30980128, 0.49732473],\n",
              "       [0.11041854, 0.44828528, 0.44129628],\n",
              "       [0.07070844, 0.43230143, 0.4969902 ],\n",
              "       [0.11176789, 0.41930825, 0.4689238 ],\n",
              "       [0.09004278, 0.45509234, 0.45486486],\n",
              "       [0.08189878, 0.45414057, 0.4639606 ],\n",
              "       [0.0563881 , 0.4692569 , 0.474355  ],\n",
              "       [0.07223684, 0.4035981 , 0.52416503],\n",
              "       [0.11111215, 0.37128294, 0.5176049 ],\n",
              "       [0.10027282, 0.44956508, 0.45016217],\n",
              "       [0.09545922, 0.41663408, 0.4879067 ],\n",
              "       [0.09314372, 0.427968  , 0.47888824],\n",
              "       [0.0951283 , 0.4089935 , 0.49587822],\n",
              "       [0.08098551, 0.33837265, 0.5806418 ],\n",
              "       [0.16335787, 0.28455478, 0.55208737],\n",
              "       [0.14601251, 0.308573  , 0.54541445],\n",
              "       [0.06195445, 0.40369347, 0.53435206],\n",
              "       [0.03653559, 0.44159588, 0.5218685 ],\n",
              "       [0.12683934, 0.33118415, 0.5419765 ],\n",
              "       [0.0810185 , 0.35929987, 0.5596816 ],\n",
              "       [0.09049147, 0.34077802, 0.56873053],\n",
              "       [0.0798205 , 0.34734902, 0.5728305 ],\n",
              "       [0.06512704, 0.38475242, 0.55012053],\n",
              "       [0.08800701, 0.36763218, 0.54436076],\n",
              "       [0.08000353, 0.33447587, 0.58552057],\n",
              "       [0.09821232, 0.33053565, 0.571252  ],\n",
              "       [0.08511471, 0.32650453, 0.58838075],\n",
              "       [0.05530242, 0.36922088, 0.57547665],\n",
              "       [0.08315223, 0.35627225, 0.56057554],\n",
              "       [0.06999293, 0.32924026, 0.60076684],\n",
              "       [0.06114667, 0.19177198, 0.74708134],\n",
              "       [0.05202102, 0.24946977, 0.6985092 ],\n",
              "       [0.02396332, 0.2890605 , 0.6869762 ],\n",
              "       [0.04189551, 0.26339003, 0.6947145 ],\n",
              "       [0.03571877, 0.23409991, 0.73018134],\n",
              "       [0.01486333, 0.29075631, 0.6943804 ],\n",
              "       [0.07425182, 0.2140417 , 0.71170646],\n",
              "       [0.01673976, 0.30273646, 0.6805238 ],\n",
              "       [0.01702038, 0.28827953, 0.69470006],\n",
              "       [0.03067514, 0.21609807, 0.7532268 ],\n",
              "       [0.03654223, 0.2504889 , 0.7129688 ],\n",
              "       [0.02339729, 0.26007366, 0.716529  ],\n",
              "       [0.0217147 , 0.2521926 , 0.7260927 ],\n",
              "       [0.03025797, 0.21605131, 0.7536907 ],\n",
              "       [0.03387838, 0.18111639, 0.7850052 ],\n",
              "       [0.03178495, 0.20275845, 0.76545656],\n",
              "       [0.02580777, 0.24246755, 0.73172474],\n",
              "       [0.02113707, 0.22287628, 0.7559867 ],\n",
              "       [0.00564845, 0.24427854, 0.750073  ],\n",
              "       [0.01571393, 0.2689152 , 0.7153709 ],\n",
              "       [0.01828362, 0.20912094, 0.77259547],\n",
              "       [0.03406494, 0.18432468, 0.78161037],\n",
              "       [0.00645076, 0.25679365, 0.7367556 ],\n",
              "       [0.01712595, 0.24121596, 0.74165803],\n",
              "       [0.02175345, 0.19723575, 0.7810108 ],\n",
              "       [0.0136419 , 0.24125159, 0.7451065 ],\n",
              "       [0.01859803, 0.22635104, 0.7550509 ],\n",
              "       [0.02412286, 0.20744395, 0.76843315],\n",
              "       [0.01423467, 0.18764178, 0.79812354],\n",
              "       [0.00996704, 0.259273  , 0.7307599 ],\n",
              "       [0.00628635, 0.2422259 , 0.75148773],\n",
              "       [0.01158221, 0.2231301 , 0.76528764],\n",
              "       [0.01211527, 0.17232771, 0.815557  ],\n",
              "       [0.01462085, 0.22558238, 0.7597968 ],\n",
              "       [0.01400448, 0.20687453, 0.7791209 ],\n",
              "       [0.00470833, 0.21222581, 0.78306586],\n",
              "       [0.02030285, 0.13450582, 0.8451913 ],\n",
              "       [0.0153022 , 0.18011439, 0.8045834 ],\n",
              "       [0.01792121, 0.17857851, 0.8035003 ],\n",
              "       [0.00890751, 0.18758771, 0.80350477],\n",
              "       [0.0094384 , 0.15188946, 0.8386721 ],\n",
              "       [0.00786132, 0.1791681 , 0.8129705 ],\n",
              "       [0.01314254, 0.15338682, 0.83347064],\n",
              "       [0.00900138, 0.14619242, 0.8448062 ],\n",
              "       [0.00988119, 0.13246839, 0.85765046],\n",
              "       [0.007237  , 0.1595929 , 0.83317006],\n",
              "       [0.00621152, 0.1777662 , 0.8160223 ],\n",
              "       [0.00850814, 0.16228183, 0.82921004],\n",
              "       [0.01470149, 0.1188108 , 0.86648774],\n",
              "       [0.01334083, 0.14276308, 0.8438961 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBgKZkhkcih6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d5b953f7-7e7d-449b-bb74-094c453b4880"
      },
      "source": [
        "    score = model.evaluate( X,y,batch_size=X.shape[0])\n",
        "    score"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r150/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 580us/sample - loss: 0.5385 - accuracy: 0.7733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5384694337844849, 0.7733333]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opWCkeObR0bc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e9c938e-4ab8-423a-e700-7163c85394b2"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'accuracy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P32ASP1Vjt0a"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8rd0jjAjyTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a834d10-5f64-45d8-cd30-2cf2abdc5455"
      },
      "source": [
        "model.save"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Sequential.save of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f56b3971e10>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiipRpe7rbVh"
      },
      "source": [
        "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
        "\n",
        "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5Du3lubr4sA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f29016c-19d8-476e-f1b8-8de0eff5cf17"
      },
      "source": [
        "input_points = 4\n",
        "hidden_layers = 10\n",
        "output_nodes=3\n",
        "\n",
        "# Initialize Sequential model\n",
        "model2 = tf.keras.models.Sequential()\n",
        "\n",
        "# Normalize the data\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides hidden layers after applying softmax for hidden layer\n",
        "model2.add(tf.keras.layers.Dense(hidden_layers, input_dim=input_points, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "# hidden to next hidden layer \n",
        "model2.add(tf.keras.layers.Dense(hidden_layers, activation='softmax'))\n",
        "\n",
        "# next-hidden to output layer \n",
        "model2.add(tf.keras.layers.Dense(output_nodes, activation='softmax'))\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=.01, decay=1e-6, momentum=0.9)\n",
        "\n",
        "# Comile the model\n",
        "model2.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X,y, epochs=100,\n",
        "          batch_size = X.shape[0])\n",
        "\n",
        "score2 = model2.evaluate( X,y,batch_size=X.shape[0])\n",
        "print('Score: ',score2)\n",
        "print('Metrics_names: ', model2.metrics_names)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 150 samples\n",
            "Epoch 1/100\n",
            "150/150 [==============================] - 0s 2ms/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 0s 37us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 0s 23us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 1.0989 - accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 13/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 14/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 15/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 16/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 17/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 18/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 19/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 20/100\n",
            "150/150 [==============================] - 0s 33us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 21/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 22/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 23/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 1.0988 - accuracy: 0.3333\n",
            "Epoch 24/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 25/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 26/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 27/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 28/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 29/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 30/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 31/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 32/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 33/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 34/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 35/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0987 - accuracy: 0.3333\n",
            "Epoch 36/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 37/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 38/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 39/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 40/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 41/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 42/100\n",
            "150/150 [==============================] - 0s 35us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 43/100\n",
            "150/150 [==============================] - 0s 75us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 44/100\n",
            "150/150 [==============================] - 0s 39us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 45/100\n",
            "150/150 [==============================] - 0s 42us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 46/100\n",
            "150/150 [==============================] - 0s 47us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 47/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 48/100\n",
            "150/150 [==============================] - 0s 29us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 49/100\n",
            "150/150 [==============================] - 0s 48us/sample - loss: 1.0986 - accuracy: 0.3333\n",
            "Epoch 50/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 51/100\n",
            "150/150 [==============================] - 0s 39us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 52/100\n",
            "150/150 [==============================] - 0s 42us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 53/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 54/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 55/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 56/100\n",
            "150/150 [==============================] - 0s 33us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 57/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 58/100\n",
            "150/150 [==============================] - 0s 23us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 59/100\n",
            "150/150 [==============================] - 0s 31us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 60/100\n",
            "150/150 [==============================] - 0s 40us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 61/100\n",
            "150/150 [==============================] - 0s 28us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 62/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 63/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0985 - accuracy: 0.3333\n",
            "Epoch 64/100\n",
            "150/150 [==============================] - 0s 53us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 65/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 66/100\n",
            "150/150 [==============================] - 0s 26us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 67/100\n",
            "150/150 [==============================] - 0s 36us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 68/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 69/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 70/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 71/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 72/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 73/100\n",
            "150/150 [==============================] - 0s 39us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 74/100\n",
            "150/150 [==============================] - 0s 35us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 75/100\n",
            "150/150 [==============================] - 0s 20us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 76/100\n",
            "150/150 [==============================] - 0s 18us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 77/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 78/100\n",
            "150/150 [==============================] - 0s 21us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "Epoch 79/100\n",
            "150/150 [==============================] - 0s 41us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 80/100\n",
            "150/150 [==============================] - 0s 22us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 81/100\n",
            "150/150 [==============================] - 0s 21us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 82/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 83/100\n",
            "150/150 [==============================] - 0s 25us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 84/100\n",
            "150/150 [==============================] - 0s 30us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 85/100\n",
            "150/150 [==============================] - 0s 23us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 86/100\n",
            "150/150 [==============================] - 0s 24us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 87/100\n",
            "150/150 [==============================] - 0s 19us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 88/100\n",
            "150/150 [==============================] - 0s 32us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 89/100\n",
            "150/150 [==============================] - 0s 33us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 90/100\n",
            "150/150 [==============================] - 0s 27us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 91/100\n",
            "150/150 [==============================] - 0s 74us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 92/100\n",
            "150/150 [==============================] - 0s 41us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 93/100\n",
            "150/150 [==============================] - 0s 49us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 94/100\n",
            "150/150 [==============================] - 0s 41us/sample - loss: 1.0983 - accuracy: 0.3333\n",
            "Epoch 95/100\n",
            "150/150 [==============================] - 0s 39us/sample - loss: 1.0982 - accuracy: 0.3333\n",
            "Epoch 96/100\n",
            "150/150 [==============================] - 0s 42us/sample - loss: 1.0982 - accuracy: 0.3333\n",
            "Epoch 97/100\n",
            "150/150 [==============================] - 0s 43us/sample - loss: 1.0982 - accuracy: 0.3333\n",
            "Epoch 98/100\n",
            "150/150 [==============================] - 0s 34us/sample - loss: 1.0982 - accuracy: 0.3333\n",
            "Epoch 99/100\n",
            "150/150 [==============================] - 0s 47us/sample - loss: 1.0982 - accuracy: 0.3333\n",
            "Epoch 100/100\n",
            "150/150 [==============================] - 0s 35us/sample - loss: 1.0982 - accuracy: 0.3333\n",
            "150/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 744us/sample - loss: 1.0984 - accuracy: 0.3333\n",
            "('Score: ', [1.0983878374099731, 0.33333334])\n",
            "('Metrics_names: ', ['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U96IeakRVWjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WFOF-NBZney",
        "colab_type": "text"
      },
      "source": [
        "After adding 2 hidden layers, I see the performance decreased. Tried to optimize it but still it is giving the same performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UzQsQZiZl_C",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}